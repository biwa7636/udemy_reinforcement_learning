{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Credit: Udemy Reinforcement Learning Lession 4 Quiz](res/images/value_computation_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $S_3$ is not the final state, $S \\neq S_F$, then $V(S_3) = E[r + \\gamma*V(S')]$ \n",
    "\n",
    "$S'$ stands for the next state, or the state that you will end up being after taking certain action. Given that, $S_3$ could lead to either $S_4$ or $S_5$ \n",
    "\n",
    "$S \\neq S_F$, then \n",
    "\n",
    "$$V(S_3) = E[r + \\gamma*V(S')] = \\sum P * (r + \\gamma*V(S') = P(S_4) * (r_3 + \\gamma * V(S_4)) + P(S_5) * (r_3 + \\gamma * V(S_5)) $$\n",
    "\n",
    "Since $r_3 = +0$ and $\\gamma = 1$, then we got \n",
    "\n",
    "$$V(S_3) = P(S_4)V(S_4) + P(S_5)V(S_5)$$\n",
    "\n",
    "$P(S_4) = 0.9$ and $P(S_5) = 0.1$, we got\n",
    "\n",
    "$$V(S_3) = 0.9V(S_4) + 0.1V(S_5)$$\n",
    "\n",
    "The next step is to calculate $V(S_4)$, and $V(S_5)$, since the final state $V(S_F)$ is known to be 0, and most importantly, the final state are the only possible next state of $S_4$ and $S_5$, then we have these equations:\n",
    "\n",
    "$$V(S_4) = r_4 + \\gamma V(S_F) = +1 + 1 * 0 = 1$$\n",
    "$$V(S_5) = r_5 + \\gamma V(S_F) = +10 + 1 * 0 = 10$$\n",
    "\n",
    "In the end, we got: \n",
    "\n",
    "$$V(S_3) = 0.9V(S_4) + 0.1V(S_5) = 0.9 * 1 + 0.1 * 10 = 1.9$$\n",
    "\n",
    "Just for the sake of completeness, we will use the same method to backward calculate $V(S_1)$ and $V(S_2)$\n",
    "\n",
    "$$V(S_1)=r_1 + \\gamma V(S_3) = 1 + 1 * 1.9 = 2.9$$\n",
    "$$V(S_2)=r_2 + \\gamma V(S_3) = 2 + 1 * 1.9 = 3.9$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Credit: Udemy Reinforcement Learning Lession 5 Quiz](res/images/estimating_from_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in estimating from data is to infer the probabily from the data. For example, the decision from $S_3$ is stochastic where there is a probability of 0.9 where it ended in $S_4$ and 0.1 probability of ending in $S_5$, without the knowledge of that, we can infer this probability by looking at the distribution in the data. \n",
    "\n",
    "In this case, we have 3 episodes. In this case, there are 2 episodes where it ended up in $S_4$ and 1 episode in $S_5$, so $P(S_4) = 2/3$ and $P(S_5) = 1/3$ \n",
    "\n",
    "$$ V(S_1) = r_1 + \\gamma V(S_3) = r_1 + \\gamma [P(S_4)(r_4 + \\gamma * V(S_F)) + P(S_5)(r_5+\\gamma * V(S_F))] $$\n",
    "\n",
    "From the data, we know the following conditions: \n",
    "\n",
    "$$r_1=1, r_4=1, r_5=10$$\n",
    "\n",
    "$$V(S_1) = 1 + (2/3 * 1 + 1/3 * 10) = 5$$\n",
    "\n",
    "After 4 episodes, the probability adjusted to be $P(S_4) = 3/4, P(S_5) = 1/4 $\n",
    "\n",
    "$$V(S_1) = 1 + (3/4 * 1 + 1/4 * 10) = 4.25$$\n",
    "\n",
    "And the theoritical calculation given the probability is 2.9, luckily the estimation is approaching to 2.9 first from 5 and then to 4.25 as we have more and more data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Credit: Udemy Reinforcement Learning Lession 5 Quiz](res/images/properties_of_learning_rate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| This | is   |\n",
    "|------|------|\n",
    "|   a  | table|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
